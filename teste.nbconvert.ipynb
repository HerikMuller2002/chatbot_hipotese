{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import numpy as np\n",
    "from re import sub\n",
    "import time\n",
    "import json\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"documents\\\\troubleshooting.xlsx\")\n",
    "df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "df_drop = df.drop(['pag','type','equipament'], axis=1)\n",
    "df_drop = df_drop.astype(str)\n",
    "df_drop = df_drop.replace(' ', 'NaN')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividir dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividir o dataframe em partes iguais\n",
    "df_parts = np.array_split(df_drop, 5)\n",
    "# criar dataframes a partir de cada parte\n",
    "df1 = df_parts[0]\n",
    "df2 = df_parts[1]\n",
    "df3 = df_parts[2]\n",
    "df4 = df_parts[3]\n",
    "df5 = df_parts[4]\n",
    "\n",
    "lista_df = [df1,df2,df3,df4,df5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api openai key\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def correcao(txt):\n",
    "  req = f\"Estou criando um sistema python qu identifica e corrige problemas de equipamentos mecânicos e elétricos. Por favor, para garantir que as palvras estejam corretas, corrija a ortografia das seguintes frases dessa lista python. ps(apenas retorne a lista corrigida): {txt}\"\n",
    "\n",
    "  completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": req}\n",
    "    ]\n",
    "  )\n",
    "  res = completion.choices[0].message.content\n",
    "  return res\n",
    "\n",
    "def traducao(txt):\n",
    "  trad = f\"fiz um problemas mecânicos e elétricos em máquinas industriais, e precisaria que vc traduzisse essa frase para portugues: {txt}\"\n",
    "\n",
    "  completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": trad}\n",
    "    ]\n",
    "  )\n",
    "  res = completion.choices[0].message.content\n",
    "  return res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando openai:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocces(dataframe):\n",
    "    rows = []\n",
    "    for idx, row in dataframe.iterrows():\n",
    "        rows.append(row.apply(lambda x: sub(r\"[;]\", \".\", x)))\n",
    "    new_dataframe = pd.DataFrame(rows).reset_index(drop=True)\n",
    "    return new_dataframe\n",
    "\n",
    "    \n",
    "def transform_col_in_lines(dataframe):\n",
    "    colunas = []\n",
    "    for col in dataframe.columns:\n",
    "        linhas = dataframe.loc[:,col]\n",
    "        colunas.append(linhas)\n",
    "    return colunas\n",
    "\n",
    "\n",
    "def api(colunas):\n",
    "    responses = []\n",
    "    cols = 0\n",
    "    for i in colunas:\n",
    "        cols += 1\n",
    "        print(f\"coluna: {cols}\")\n",
    "        i = list(OrderedDict.fromkeys(i))\n",
    "        txt = json.dumps(i)\n",
    "        response = correcao(txt)\n",
    "        responses.append(response)\n",
    "    return responses\n",
    "\n",
    "\n",
    "def preprocces_api(responses):\n",
    "    list_responses_process = []\n",
    "    for i in responses:\n",
    "        i = i.lower()\n",
    "        i = sub('\\n', '\"', i)\n",
    "        frases = filter(lambda x: x != '', i.split('\"'))\n",
    "        frases = list(map(str.strip, frases))\n",
    "        frases = list(filter(bool, frases))\n",
    "        list_responses_process.append(frases)\n",
    "    for x in list_responses_process:\n",
    "        for i in range(len(x)-1, -1, -1):\n",
    "            if x[i] == '[' or x[i] == ']' or x[i] == ',' or x[i] == '-':\n",
    "                del x[i]\n",
    "            # x[i] = x[i].strip()\n",
    "            # if x[i].endswith('.'):\n",
    "            #     x[i] = x[i].rstrip('.')\n",
    "            # if x[i].startswith('-'):\n",
    "            #     x[i] = x[i].lstrip('-')\n",
    "            # elif x[i].startswith('.'):\n",
    "            #     x[i] = x[i].lstrip('.')\n",
    "            # elif x[i].startswith('*'):\n",
    "            #     x[i] = x[i].lstrip('*')\n",
    "    return list_responses_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coluna: 1\n",
      "coluna: 2\n",
      "coluna: 3\n",
      "37\n",
      "97\n",
      "96\n",
      "\n",
      "37\n",
      "96\n",
      "93\n"
     ]
    }
   ],
   "source": [
    "dataframe = preprocces(df3)\n",
    "colunas = transform_col_in_lines(dataframe)\n",
    "responses = api(colunas)\n",
    "list_response_process = preprocces_api(responses)\n",
    "\n",
    "print(len(list_response_process[0]))\n",
    "print(len(list_response_process[1]))\n",
    "print(len(list_response_process[2]))\n",
    "print()\n",
    "print(len(list(OrderedDict.fromkeys(list_response_process[0]))))\n",
    "print(len(list(OrderedDict.fromkeys(list_response_process[1]))))\n",
    "print(len(list(OrderedDict.fromkeys(list_response_process[2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "97\n",
      "94\n"
     ]
    }
   ],
   "source": [
    "colunas = []\n",
    "for col in df3.columns:\n",
    "    linhas = df3.loc[:,col]\n",
    "    colunas.append(linhas)\n",
    "\n",
    "print(len(list(OrderedDict.fromkeys(colunas[0]))))\n",
    "print(len(list(OrderedDict.fromkeys(colunas[1]))))\n",
    "print(len(list(OrderedDict.fromkeys(colunas[2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 2 (char 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m list_response_process \u001b[39m=\u001b[39m preprocces_api(responses[\u001b[39m2\u001b[39;49m])\n",
      "Cell \u001b[1;32mIn[82], line 34\u001b[0m, in \u001b[0;36mpreprocces_api\u001b[1;34m(responses)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m responses:\n\u001b[0;32m     33\u001b[0m     i \u001b[39m=\u001b[39m i\u001b[39m.\u001b[39mlower()\n\u001b[1;32m---> 34\u001b[0m     i \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mloads(i)\n\u001b[0;32m     35\u001b[0m     frases \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mstr\u001b[39m\u001b[39m.\u001b[39mstrip, frases))\n\u001b[0;32m     36\u001b[0m     frases \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mfilter\u001b[39m(\u001b[39mbool\u001b[39m, frases))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, s, _w\u001b[39m=\u001b[39mWHITESPACE\u001b[39m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[0;32m    338\u001b[0m     end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 2 (char 1)"
     ]
    }
   ],
   "source": [
    "list_response_process = preprocces_api(responses[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_list_df = []\n",
    "\n",
    "# cont = 0\n",
    "# for dataframe in lista_df:\n",
    "#     cont += 1\n",
    "#     print(f'df: {cont}')\n",
    "\n",
    "#     dataframe = preprocces(dataframe)\n",
    "#     colunas = transform_col_in_lines(dataframe)\n",
    "#     responses = api(colunas)\n",
    "#     list_response_process = preprocces_api(responses)\n",
    "#     new_list_df.append(list_response_process)\n",
    "    \n",
    "#     print(len(list_response_process[0]))\n",
    "#     print(len(list_response_process[1]))\n",
    "#     print(len(list_response_process[2]))\n",
    "#     print()\n",
    "#     print(len(list(OrderedDict.fromkeys(list_response_process[0]))))\n",
    "#     print(len(list(OrderedDict.fromkeys(list_response_process[1]))))\n",
    "#     print(len(list(OrderedDict.fromkeys(list_response_process[2]))))\n",
    "\n",
    "#     time.sleep(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coluna.txt','w',encoding='utf-8') as f:\n",
    "    cont = 0\n",
    "    for i in list(OrderedDict.fromkeys(colunas[2])):\n",
    "        f.write(f'{cont} - {i}')\n",
    "        f.write('\\n')\n",
    "        cont += 1\n",
    "\n",
    "with open('corrigida.txt','w',encoding='utf-8')as g:\n",
    "    cont = 0\n",
    "    for i in list(OrderedDict.fromkeys(list_response_process[2])):\n",
    "    # for i in list_response_process[1]:\n",
    "        g.write(f'{cont} - {i}')\n",
    "        g.write('\\n')\n",
    "        cont += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicionário da lista corrigida em relação a original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista1 = list_response_process[1]\n",
    "# lista1 = list(OrderedDict.fromkeys(list_response_process[0]))\n",
    "lista2 = list(OrderedDict.fromkeys(colunas[1]))\n",
    "lista3 = colunas[1]\n",
    "\n",
    "for j in range(len(lista2)):\n",
    "    lista2[j] = lista2[j].lower()\n",
    "\n",
    "for i in range(len(lista1)):\n",
    "    lista1[i] = lista1[i].lower()\n",
    "    lista1[i] = lista1[i].strip()\n",
    "    if lista1[i].endswith('.'):\n",
    "        lista1[i] = lista1[i].rstrip('.')\n",
    "\n",
    "dicionario = dict(zip(lista1, lista2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicionário de valores repetidos na lista original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_repetidos(lista):\n",
    "    for j in range(len(lista)):\n",
    "        lista[j] = lista[j].lower()\n",
    "    repetidos = {}\n",
    "    for i, item in enumerate(lista):\n",
    "        if item not in repetidos:\n",
    "            repetidos[item] = [i]\n",
    "        else:\n",
    "            repetidos[item].append(i)\n",
    "    return repetidos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reparando a lista corrigida para a original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "repetidos = encontrar_repetidos(lista3)\n",
    "\n",
    "n = (len(lista3))\n",
    "lista_matriz = [None] * n\n",
    "\n",
    "for chave,valor in dicionario.items():\n",
    "    id = repetidos[valor]\n",
    "    if type(id) != list:\n",
    "        id = [id]\n",
    "    for i in id:\n",
    "        lista_matriz[i] = chave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coluna2.json', 'w',encoding='utf-8') as arquivo:\n",
    "    json.dump(lista_matriz, arquivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coluna3.json', 'r', encoding='utf-8') as arquivo:\n",
    "    string = arquivo.read()\n",
    "    lst = json.loads(string)\n",
    "\n",
    "for id, i in enumerate(lst):\n",
    "    if 'stagger the ring butts by placing the first' in i:\n",
    "        print(id)\n",
    "lst[94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correcao.to_excel('df_correcao.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo as colunas em listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_listas = []\n",
    "for df in lista_df:\n",
    "    listas = [[], [], []]\n",
    "    for num_coluna in range(len(df.columns)):\n",
    "        nome_coluna = df.columns[num_coluna]\n",
    "        lista = listas[num_coluna]\n",
    "        for linha in df.loc[:,nome_coluna]:\n",
    "            lista.append(linha)\n",
    "    lista_listas.append(listas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "lista_listas = [[[],[],[]],[[],[],[]],[[],[],[]],[[],[],[]],[[],[],[]],[[],[],[]],[[],[],[]],[[],[],[]],[[],[],[]],[[],[],[]],[[],[],[]],[[],[],[]]]\n",
    "new_lista_listas = lista_listas\n",
    "parte = 0\n",
    "for num_df in range(len(lista_df)):\n",
    "    parte+=1\n",
    "    print(f'parte{parte}')\n",
    "    col = 0\n",
    "    for num_coluna in range(len(lista_df[num_df].columns)):\n",
    "        col += 1\n",
    "        print(f\"col{col}\")\n",
    "        nome_coluna = lista_df[num_df].columns[num_coluna]\n",
    "        lista = []\n",
    "        for linha in lista_df[num_df][nome_coluna]:\n",
    "            lista.append(linha)\n",
    "        # juntar todos os elementos da lista em uma string separada por '#'\n",
    "        values = \"#\".join(lista)\n",
    "        correc = correcao(values)\n",
    "        new_lista_listas[num_df][num_coluna].append(correc)\n",
    "        lista_listas[num_df][num_coluna].append(values)\n",
    "        time.sleep(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lista_backup = new_lista_listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_listas[3][1][0].split('#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for x in range(len(lista_df)):\n",
    "    colunas = []\n",
    "    for i in range(len(df2.columns)):\n",
    "        linhas = new_lista_listas[x][i][0].split('#')\n",
    "        for j in linhas:\n",
    "            count += 1\n",
    "print(count/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt = pd.read_excel(\"df_gpt.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partes = []\n",
    "for x in range(len(lista_df)):\n",
    "    colunas = []\n",
    "    for i in range(len(df_gpt.columns)):\n",
    "        df_coluna = df_gpt.loc[:,df_gpt.columns[i]]\n",
    "        linhas = new_lista_listas[x][i][0].split('#')\n",
    "        for j in linhas:\n",
    "            df_coluna.loc[len(df_coluna)] = j\n",
    "        colunas.append(df_coluna)\n",
    "    df_coluna_temp = pd.concat([colunas[0],colunas[1],colunas[2]], axis=1)\n",
    "    partes.append(df_coluna_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in partes:\n",
    "    df_concatenado = pd.concat([df_gpt,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_concatenado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# new_df = df2\n",
    "# parte = 0\n",
    "# new_list = lista_lista\n",
    "# for i in range(len(lista_lista)):\n",
    "#     parte+=1\n",
    "#     print(f'parte{parte}')\n",
    "#     col = 0\n",
    "#     for j in range(len(lista_lista[i])):\n",
    "#         col += 1\n",
    "#         print(f\"col{col}\")\n",
    "#         values = '#'.join(lista_lista[i][j])\n",
    "#         correc = correcao(values)\n",
    "#         new_list[i][j] = list(correc)\n",
    "\n",
    "\n",
    "# df_correcao = parte1\n",
    "# values_lista = '# '.join(listas[1])\n",
    "# correc = correcao(values_lista)\n",
    "# df_correcao.loc[i,j]=correc\n",
    "    # trad = traducao(correc)\n",
    "    # df_traducao.loc[i,j]=trad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(values_lista)\n",
    "print(correc)\n",
    "\n",
    "a1 = values_lista.split('#')\n",
    "b1 = correc.split('#')\n",
    "\n",
    "print(len(a1))\n",
    "print(len(b1))\n",
    "# print(listas[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando excel com dataframe corrigido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correcao.to_excel('df_correcao2.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparando os dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"documents\\\\troubleshooting.xlsx\")\n",
    "data2 = pd.read_excel(\"df_correcao2.xlsx\")\n",
    "print(len(df2))\n",
    "print(len(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = 0\n",
    "nok = 0\n",
    "for num_coluna in range(len(data2)):\n",
    "    if data.loc[num_coluna,'cause'] == data2.loc[num_coluna,'cause']:\n",
    "        ok += 1\n",
    "    else:\n",
    "        nok += 1\n",
    "\n",
    "print(ok)\n",
    "print(nok)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
