{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import os\n",
    "import openai\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"documents\\\\troubleshooting.xlsx\")\n",
    "df_drop = df.drop(['pag','type','equipament'], axis=1)\n",
    "df_drop = df_drop.astype(str)\n",
    "df_drop = df_drop.replace(' ', 'NaN')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividir dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividir o dataframe em partes iguais\n",
    "df_parts = np.array_split(df_drop, 5)\n",
    "# criar dataframes a partir de cada parte\n",
    "df1 = df_parts[0]\n",
    "df2 = df_parts[1]\n",
    "df3 = df_parts[2]\n",
    "df4 = df_parts[3]\n",
    "df5 = df_parts[4]\n",
    "\n",
    "lista_df = [df1,df2,df3,df4,df5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api openai key\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def correcao(txt):\n",
    "  req = f\"corrija a ortorgráfia dessa lista de frases tecnicas de engenharia em ingles, me retorne a lista de frase corrigidas exatamente na mesma estrutura, cada frase separada por '#', e se tiver frases repetidas, corrijas mesmo assim. aqui está: {txt}\"\n",
    "\n",
    "  completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0301\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"Você é um corretor ortográfico de textos técnicos em inglês, de engenharia: mecânica e elétrica\"},\n",
    "      {\"role\": \"user\", \"content\": req}\n",
    "    ]\n",
    "  )\n",
    "  res = completion.choices[0].message.content\n",
    "  return res\n",
    "\n",
    "def traducao(txt):\n",
    "  trad = f\"estou fazendo uma planilha com problemas mecânicos e elétricos em máquinas industriais, e precisaria que vc traduzisse essa frase para portugues: {txt}\"\n",
    "\n",
    "  completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": trad}\n",
    "    ]\n",
    "  )\n",
    "  res = completion.choices[0].message.content\n",
    "  return res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando openai:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo as colunas em listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = []\n",
    "for col in df1.columns:\n",
    "    linhas = df1.loc[:,col]\n",
    "    txt = '#'.join(linhas)\n",
    "    colunas.append(txt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "for i in colunas:\n",
    "    response = correcao(i)\n",
    "    responses.append(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separadores = ['#', '\\n']\n",
    "lista = [responses[0]]\n",
    "for sep in separadores:\n",
    "    nova_lista = []\n",
    "    for item in lista:\n",
    "        nova_lista.extend(item.split(sep))\n",
    "    lista = nova_lista\n",
    "lista = [elem.strip() for elem in lista if elem.strip()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### valores repetidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import sub\n",
    "list_col = colunas[1].split('#')\n",
    "for i in range(len(lista)):\n",
    "    lista[i] = lista[i].lower()\n",
    "    lista[i] = sub(r\"[.]\", \"\", lista[i])\n",
    "for i in range(len(list_col)):\n",
    "    list_col[i] = list_col[i].lower()\n",
    "    list_col[i] = sub(r\"[.]\", \"\", list_col[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista1 = list(set(list_col))\n",
    "lista2 = list(set(lista))\n",
    "\n",
    "# Elementos exclusivos de lista1\n",
    "exclusivos_lista1 = []\n",
    "# Elementos exclusivos de lista2\n",
    "exclusivos_lista2 = []\n",
    "\n",
    "for i in lista1:\n",
    "    if i not in lista2:\n",
    "        exclusivos_lista1.append(i)\n",
    "\n",
    "for j in lista2:\n",
    "    if j not in lista1:\n",
    "        exclusivos_lista2.append(j)\n",
    "\n",
    "print(len(exclusivos_lista1))\n",
    "print(len(exclusivos_lista2))\n",
    "\n",
    "print(f\"Elementos exclusivos de lista1: {exclusivos_lista1}\")\n",
    "print(f\"Elementos exclusivos de lista2: {exclusivos_lista2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((list_col))\n",
    "print(len(list(set(list_col))))\n",
    "print(lista)\n",
    "print(len(lista))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_rep = []\n",
    "for i in range(len(df1.columns)):\n",
    "    repetidas = {}\n",
    "    coluna = colunas[i].split('#')\n",
    "    for index, frase in enumerate(coluna):\n",
    "        if frase in repetidas:\n",
    "            repetidas[frase].append(index)\n",
    "        else:\n",
    "            repetidas[frase] = [index]\n",
    "    sent_rep.append(repetidas)\n",
    "\n",
    "    # for elemento, indices in repetidos.items():\n",
    "    #     if len(indices) > 1:\n",
    "print(sent_rep[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import sub\n",
    "for i in range(len(sent_rep[0])):\n",
    "    sent_rep[0][i] = sent_rep[0][i].lower()\n",
    "    sent_rep[0][i] = sub(r\"[.]\", \"\", sent_rep[0][i])\n",
    "for i in range(len(list_col)):\n",
    "    list_col[i] = list_col[i].lower()\n",
    "    list_col[i] = sub(r\"[.]\", \"\", list_col[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verificando os elementos das listas corrigidas e da coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista1 = list(set(list_col))\n",
    "lista2 = list(sent_rep[1])\n",
    "\n",
    "# Elementos exclusivos de lista1\n",
    "exclusivos_lista1 = []\n",
    "# Elementos exclusivos de lista2\n",
    "exclusivos_lista2 = []\n",
    "\n",
    "for i in lista1:\n",
    "    if i not in lista2:\n",
    "        exclusivos_lista1.append(i)\n",
    "\n",
    "for j in lista2:\n",
    "    if j not in lista1:\n",
    "        exclusivos_lista2.append(j)\n",
    "\n",
    "print(len(exclusivos_lista1))\n",
    "print(len(exclusivos_lista2))\n",
    "\n",
    "print(f\"Elementos exclusivos de lista1: {exclusivos_lista1}\")\n",
    "print(f\"Elementos exclusivos de lista2: {exclusivos_lista2}\")\n",
    "\n",
    "print(lista1)\n",
    "print(len(lista1))\n",
    "print(lista2)\n",
    "print(len(lista2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time assincrono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def send_requests(num=0):\n",
    "    # Variáveis de controle do tempo\n",
    "    start_time = time.monotonic()\n",
    "    min_interval = 30  # tempo mínimo entre requisições em segundos\n",
    "    reqs_per_min = 3  # número máximo de requisições por minuto\n",
    "    # req_count = 0  # contador de requisições\n",
    "    req_count = num\n",
    "    \n",
    "    # Loop de envio de requisições\n",
    "    while True:\n",
    "        # Verifica se já atingiu o limite de requisições por minuto\n",
    "        if req_count >= reqs_per_min:\n",
    "            elapsed_time = time.monotonic() - start_time\n",
    "            if elapsed_time < 60:\n",
    "                sleep_time = 60 - elapsed_time\n",
    "                print(f\"Esperando {sleep_time:.2f} segundos para enviar nova requisição...\")\n",
    "                await asyncio.sleep(sleep_time)\n",
    "            start_time = time.monotonic()\n",
    "            req_count = num\n",
    "\n",
    "        # Envia a requisição\n",
    "        txt = \"leak in suction piipe\"\n",
    "        res = await correcao(txt)\n",
    "        print(res)\n",
    "\n",
    "        # Atualiza as variáveis de controle\n",
    "        req_count += 1\n",
    "        await asyncio.sleep(min_interval)\n",
    "\n",
    "# # Executa o loop de envio de requisições\n",
    "# asyncio.run(send_requests())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gingerit - correção grámatica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gingerit.gingerit import GingerIt\n",
    "\n",
    "def correcao_gingerit(frase):\n",
    "    # Cria uma instância do objeto Gingerit\n",
    "    parser = GingerIt()\n",
    "\n",
    "    # Executa a correção ortográfica usando o Gingerit\n",
    "    correcao = parser.parse(frase)\n",
    "\n",
    "    return correcao['result']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correção de todos os elementos do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correcao = df2\n",
    "count = 0\n",
    "for num_coluna in range (len(df2)):\n",
    "    for j in df2.columns:\n",
    "        value = df2.loc[num_coluna,j]\n",
    "        a = correcao(value)\n",
    "        print(a)\n",
    "        df_correcao.loc[num_coluna,j]=a\n",
    "    count += 1\n",
    "    # print(count)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo as colunas em listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_listas = []\n",
    "for df in lista_df:\n",
    "    listas = [[], [], []]\n",
    "    for num_coluna in range(len(df.columns)):\n",
    "        nome_coluna = df.columns[num_coluna]\n",
    "        lista = listas[num_coluna]\n",
    "        for linha in df.loc[:,nome_coluna]:\n",
    "            lista.append(linha)\n",
    "    lista_listas.append(listas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "lista_listas = [[[],[],[]],[[],[],[]],[[],[],[]],[[],[],[]],[[],[],[]],[[],[],[]],[[],[],[]],[[],[],[]],[[],[],[]],[[],[],[]],[[],[],[]],[[],[],[]]]\n",
    "new_lista_listas = lista_listas\n",
    "parte = 0\n",
    "for num_df in range(len(lista_df)):\n",
    "    parte+=1\n",
    "    print(f'parte{parte}')\n",
    "    col = 0\n",
    "    for num_coluna in range(len(lista_df[num_df].columns)):\n",
    "        col += 1\n",
    "        print(f\"col{col}\")\n",
    "        nome_coluna = lista_df[num_df].columns[num_coluna]\n",
    "        lista = []\n",
    "        for linha in lista_df[num_df][nome_coluna]:\n",
    "            lista.append(linha)\n",
    "        # juntar todos os elementos da lista em uma string separada por '#'\n",
    "        values = \"#\".join(lista)\n",
    "        correc = correcao(values)\n",
    "        new_lista_listas[num_df][num_coluna].append(correc)\n",
    "        lista_listas[num_df][num_coluna].append(values)\n",
    "        time.sleep(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lista_backup = new_lista_listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_listas[3][1][0].split('#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for x in range(len(lista_df)):\n",
    "    colunas = []\n",
    "    for i in range(len(df2.columns)):\n",
    "        linhas = new_lista_listas[x][i][0].split('#')\n",
    "        for j in linhas:\n",
    "            count += 1\n",
    "print(count/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt = pd.read_excel(\"df_gpt.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partes = []\n",
    "for x in range(len(lista_df)):\n",
    "    colunas = []\n",
    "    for i in range(len(df_gpt.columns)):\n",
    "        df_coluna = df_gpt.loc[:,df_gpt.columns[i]]\n",
    "        linhas = new_lista_listas[x][i][0].split('#')\n",
    "        for j in linhas:\n",
    "            df_coluna.loc[len(df_coluna)] = j\n",
    "        colunas.append(df_coluna)\n",
    "    df_coluna_temp = pd.concat([colunas[0],colunas[1],colunas[2]], axis=1)\n",
    "    partes.append(df_coluna_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in partes:\n",
    "    df_concatenado = pd.concat([df_gpt,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_concatenado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# new_df = df2\n",
    "# parte = 0\n",
    "# new_list = lista_lista\n",
    "# for i in range(len(lista_lista)):\n",
    "#     parte+=1\n",
    "#     print(f'parte{parte}')\n",
    "#     col = 0\n",
    "#     for j in range(len(lista_lista[i])):\n",
    "#         col += 1\n",
    "#         print(f\"col{col}\")\n",
    "#         values = '#'.join(lista_lista[i][j])\n",
    "#         correc = correcao(values)\n",
    "#         new_list[i][j] = list(correc)\n",
    "\n",
    "\n",
    "# df_correcao = parte1\n",
    "# values_lista = '# '.join(listas[1])\n",
    "# correc = correcao(values_lista)\n",
    "# df_correcao.loc[i,j]=correc\n",
    "    # trad = traducao(correc)\n",
    "    # df_traducao.loc[i,j]=trad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(values_lista)\n",
    "print(correc)\n",
    "\n",
    "a1 = values_lista.split('#')\n",
    "b1 = correc.split('#')\n",
    "\n",
    "print(len(a1))\n",
    "print(len(b1))\n",
    "# print(listas[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando excel com dataframe corrigido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_correcao.to_excel('df_correcao2.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparando os dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"documents\\\\troubleshooting.xlsx\")\n",
    "data2 = pd.read_excel(\"df_correcao2.xlsx\")\n",
    "print(len(df2))\n",
    "print(len(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = 0\n",
    "nok = 0\n",
    "for num_coluna in range(len(data2)):\n",
    "    if data.loc[num_coluna,'cause'] == data2.loc[num_coluna,'cause']:\n",
    "        ok += 1\n",
    "    else:\n",
    "        nok += 1\n",
    "\n",
    "print(ok)\n",
    "print(nok)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
