{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import numpy as np\n",
    "from re import sub, compile\n",
    "import time\n",
    "import json\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_excel(r\"documents\\en_troubleshooting.xlsx\")\n",
    "# df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "# df_drop = df.drop(['pag','type','equipament'], axis=1)\n",
    "# df_drop = df_drop.astype(str)\n",
    "# df_drop = df_drop.applymap(lambda x: x[:-1] if x.endswith('.') else x)\n",
    "# df_drop = df_drop.applymap(lambda x: x[1:] if x.startswith('-') else x)\n",
    "# # df_drop = df_drop.replace(' ', 'NaN')\n",
    "\n",
    "df = pd.read_excel(r\"documents\\en_troubleshooting.xlsx\")\n",
    "df_drop = df.drop(['id','pag','type','equipament'], axis=1)\n",
    "df = df_drop.astype(str)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividir dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividir o dataframe em partes iguais\n",
    "df_parts = np.array_split(df_drop, 5)\n",
    "# criar dataframes a partir de cada parte\n",
    "df1 = df_parts[0]\n",
    "df2 = df_parts[1]\n",
    "df3 = df_parts[2]\n",
    "df4 = df_parts[3]\n",
    "df5 = df_parts[4]\n",
    "\n",
    "lista_df = [df1,df2,df3,df4,df5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api openai key\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def correcao(txt):\n",
    "  req = f\"Estou criando um sistema python que identifica e corrige problemas de equipamentos mecânicos e elétricos. Por favor, para garantir que as palvras estejam corretas, corrija a ortografia das seguintes frases dessa lista python. ps(apenas retorne a lista corrigida): {txt}\"\n",
    "\n",
    "  completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": req}\n",
    "    ]\n",
    "  )\n",
    "  res = completion.choices[0].message.content\n",
    "  return res\n",
    "\n",
    "def traducao(txt):\n",
    "  trad = f\"Estou criando um sistema python que identifica e corrige problemas de equipamentos mecânicos e elétricos. Por favor, para garantir que as palvras estejam corretas, traduza essas frases para portugues: {txt}\"\n",
    "\n",
    "  completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": trad}\n",
    "    ]\n",
    "  )\n",
    "  res = completion.choices[0].message.content\n",
    "  return res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando openai:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocces(dataframe):\n",
    "    try:\n",
    "        rows = []\n",
    "        for idx, row in dataframe.iterrows():\n",
    "            rows.append(row.apply(lambda x: sub(r\"[;]\", \".\", x)))\n",
    "        new_dataframe = pd.DataFrame(rows).reset_index(drop=True)\n",
    "        return new_dataframe\n",
    "    except AttributeError:\n",
    "        for i in range(len(dataframe)):\n",
    "            dataframe[i] = sub(r\"[;]\", \".\", dataframe[i])\n",
    "        return dataframe\n",
    "\n",
    "    \n",
    "def transform_col_in_lines(dataframe):\n",
    "    colunas = []\n",
    "    for col in dataframe.columns:\n",
    "        linhas = dataframe.loc[:,col]\n",
    "        colunas.append(linhas)\n",
    "    return colunas\n",
    "\n",
    "\n",
    "def api(colunas):\n",
    "    responses = []\n",
    "    cols = 0\n",
    "    for i in colunas:\n",
    "        cols += 1\n",
    "        print(f\"coluna: {cols}\")\n",
    "        i = list(OrderedDict.fromkeys(i))\n",
    "        txt = json.dumps(i)\n",
    "        response = traducao(txt)\n",
    "        responses.append(response)\n",
    "    return responses\n",
    "\n",
    "\n",
    "def preprocces_api(responses):\n",
    "    list_responses_process = []\n",
    "    for i in responses:\n",
    "        i = i.lower()\n",
    "        i = sub(r'\\n', '', i)\n",
    "        i = sub(r'\\s+', ' ', i)\n",
    "        try:\n",
    "            i = json.loads(i)\n",
    "        except:\n",
    "            i = filter(lambda x: x != '', i.split('\"'))\n",
    "        i = list(map(str.strip, i))\n",
    "        i = list(filter(bool, i))\n",
    "        list_responses_process.append(i)\n",
    "    for x in list_responses_process:\n",
    "        for i in range(len(x)-1, -1, -1):\n",
    "            if x[i] == '[' or x[i] == ']' or x[i] == ',' or x[i] == '-':\n",
    "                del x[i]\n",
    "            # x[i] = x[i].strip()\n",
    "            # if x[i].endswith('.'):\n",
    "            #     x[i] = x[i].rstrip('.')\n",
    "            # if x[i].startswith('-'):\n",
    "            #     x[i] = x[i].lstrip('-')\n",
    "            # elif x[i].startswith('.'):\n",
    "            #     x[i] = x[i].lstrip('.')\n",
    "            # elif x[i].startswith('*'):\n",
    "            #     x[i] = x[i].lstrip('*')\n",
    "    return list_responses_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe = preprocces(df5)\n",
    "# colunas = transform_col_in_lines(dataframe)\n",
    "\n",
    "# # meio = len(colunas[0]) // 2\n",
    "# # parte1 = [colunas[0][:meio]]\n",
    "# # parte2 = [colunas[0][meio:]]\n",
    "# # responses1 = api(parte1)\n",
    "# # responses2 = api(parte2)\n",
    "\n",
    "# responses = api(colunas)\n",
    "# list_response_process = preprocces_api(responses)\n",
    "\n",
    "# print(len(list_response_process[0]))\n",
    "# print(len(list_response_process[1]))\n",
    "# print(len(list_response_process[2]))\n",
    "# print()\n",
    "# print(len(list(OrderedDict.fromkeys(list_response_process[0]))))\n",
    "# print(len(list(OrderedDict.fromkeys(list_response_process[1]))))\n",
    "# print(len(list(OrderedDict.fromkeys(list_response_process[2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df: 1\n",
      "coluna: 1\n",
      "coluna: 2\n",
      "coluna: 3\n",
      "\n",
      "qtd linhas nas colunas: 25\n",
      "qtd linhas nas colunas: 98\n",
      "qtd linhas nas colunas: 82\n",
      "qtd linhas corrigidas: 26\n",
      "qtd linhas corrigidas: 99\n",
      "qtd linhas corrigidas: 80\n",
      "\n",
      "df: 2\n",
      "coluna: 1\n",
      "coluna: 2\n",
      "coluna: 3\n",
      "\n",
      "qtd linhas nas colunas: 31\n",
      "qtd linhas nas colunas: 98\n",
      "qtd linhas nas colunas: 100\n",
      "qtd linhas corrigidas: 1\n",
      "qtd linhas corrigidas: 99\n",
      "qtd linhas corrigidas: 7\n",
      "\n",
      "df: 3\n",
      "coluna: 1\n",
      "coluna: 2\n",
      "coluna: 3\n",
      "\n",
      "qtd linhas nas colunas: 37\n",
      "qtd linhas nas colunas: 96\n",
      "qtd linhas nas colunas: 92\n",
      "qtd linhas corrigidas: 37\n",
      "qtd linhas corrigidas: 96\n",
      "qtd linhas corrigidas: 56\n",
      "\n",
      "df: 4\n",
      "coluna: 1\n",
      "coluna: 2\n",
      "coluna: 3\n",
      "\n",
      "qtd linhas nas colunas: 27\n",
      "qtd linhas nas colunas: 101\n",
      "qtd linhas nas colunas: 87\n",
      "qtd linhas corrigidas: 28\n",
      "qtd linhas corrigidas: 102\n",
      "qtd linhas corrigidas: 88\n",
      "\n",
      "df: 5\n",
      "coluna: 1\n",
      "coluna: 2\n",
      "coluna: 3\n",
      "\n",
      "qtd linhas nas colunas: 40\n",
      "qtd linhas nas colunas: 93\n",
      "qtd linhas nas colunas: 94\n",
      "qtd linhas corrigidas: 43\n",
      "qtd linhas corrigidas: 92\n",
      "qtd linhas corrigidas: 80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_list_df = []\n",
    "\n",
    "cont = 0\n",
    "for dataframe in lista_df:\n",
    "    cont += 1\n",
    "    print(f'df: {cont}')\n",
    "\n",
    "    # dataframe = preprocces(dataframe)\n",
    "    colunas = transform_col_in_lines(dataframe)\n",
    "    responses = api(colunas)\n",
    "    list_response_process = preprocces_api(responses)\n",
    "    new_list_df.append(list_response_process)\n",
    "    \n",
    "    print()\n",
    "    print(f\"qtd linhas nas colunas: {len(list(OrderedDict.fromkeys(colunas[0])))}\")\n",
    "    print(f\"qtd linhas nas colunas: {len(list(OrderedDict.fromkeys(colunas[1])))}\")\n",
    "    print(f\"qtd linhas nas colunas: {len(list(OrderedDict.fromkeys(colunas[2])))}\")\n",
    "    print(f\"qtd linhas corrigidas: {len(list(OrderedDict.fromkeys(list_response_process[0])))}\")\n",
    "    print(f\"qtd linhas corrigidas: {len(list(OrderedDict.fromkeys(list_response_process[1])))}\")\n",
    "    print(f\"qtd linhas corrigidas: {len(list(OrderedDict.fromkeys(list_response_process[2])))}\")\n",
    "    print()\n",
    "\n",
    "    time.sleep(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns\n",
    "data = new_list_df[0]\n",
    "df_trad1 = pd.DataFrame({cols[0]:data[0],cols[1]:data[1],cols[2]:data[2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = transform_col_in_lines(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coluna.txt','w',encoding='utf-8') as f:\n",
    "    cont = 0\n",
    "    for i in list(OrderedDict.fromkeys(colunas[0])):\n",
    "        f.write(f'{cont} - {i}')\n",
    "        f.write('\\n')\n",
    "        cont += 1\n",
    "\n",
    "with open('corrigida.txt','w',encoding='utf-8')as g:\n",
    "    cont = 0\n",
    "    for i in list(OrderedDict.fromkeys(new_list_df[0][0])):\n",
    "    # for i in list_response_process[2]:\n",
    "        g.write(f'{cont} - {i}')\n",
    "        g.write('\\n')\n",
    "        cont += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicionário da lista corrigida em relação a original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista1 = list(OrderedDict.fromkeys(list_response_process[2]))\n",
    "# lista1 = list_response_process[2]\n",
    "lista2 = list(OrderedDict.fromkeys(a))\n",
    "lista3 = colunas[2]\n",
    "\n",
    "for j in range(len(lista2)):\n",
    "    lista2[j] = lista2[j].lower()\n",
    "\n",
    "for i in range(len(lista1)):\n",
    "    lista1[i] = lista1[i].lower()\n",
    "    lista1[i] = lista1[i].strip()\n",
    "    if lista1[i].endswith('.'):\n",
    "        lista1[i] = lista1[i].rstrip('.')\n",
    "\n",
    "dicionario = dict(zip(lista1, lista2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicionário de valores repetidos na lista original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_repetidos(lista):\n",
    "    for j in range(len(lista)):\n",
    "        lista[j] = lista[j].lower()\n",
    "    repetidos = {}\n",
    "    for i, item in enumerate(lista):\n",
    "        if item not in repetidos:\n",
    "            repetidos[item] = [i]\n",
    "        else:\n",
    "            repetidos[item].append(i)\n",
    "    return repetidos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reparando a lista corrigida para a original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repetidos = encontrar_repetidos(lista3)\n",
    "\n",
    "n = (len(lista3))\n",
    "lista_matriz = [None] * n\n",
    "\n",
    "for chave,valor in dicionario.items():\n",
    "    id = repetidos[valor]\n",
    "    if type(id) != list:\n",
    "        id = [id]\n",
    "    for i in id:\n",
    "        lista_matriz[i] = chave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coluna3.json', 'w',encoding='utf-8') as arquivo:\n",
    "    json.dump(lista_matriz, arquivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coluna3.json', 'r', encoding='utf-8') as arquivo:\n",
    "    string = arquivo.read()\n",
    "    lst = json.loads(string)\n",
    "len(lst)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### criando um novo df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'ingles\\df5\\coluna1.json', 'r', encoding='utf-8') as arquivo:\n",
    "    string = arquivo.read()\n",
    "    coluna1 = json.loads(string)\n",
    "with open(r'ingles\\df5\\coluna2.json', 'r', encoding='utf-8') as arquivo:\n",
    "    string = arquivo.read()\n",
    "    coluna2 = json.loads(string)\n",
    "with open(r'ingles\\df5\\coluna3.json', 'r', encoding='utf-8') as arquivo:\n",
    "    string = arquivo.read()\n",
    "    coluna3 = json.loads(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\"problem\":coluna1, \"cause\":coluna2, \"action\":coluna3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({\"problem\":coluna1, \"cause\":coluna2, \"action\":coluna3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({\"problem\":coluna1, \"cause\":coluna2, \"action\":coluna3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame({\"problem\":coluna1, \"cause\":coluna2, \"action\":coluna3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.DataFrame({\"problem\":coluna1, \"cause\":coluna2, \"action\":coluna3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.shape)\n",
    "print(df2.shape)\n",
    "print(df3.shape)\n",
    "print(df4.shape)\n",
    "print(df5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df1, df2, df3, df4, df5], axis=0).resetindex()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando excel com dataframe corrigido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop.to_excel('df_correcao.xlsx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparando os dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"documents\\\\troubleshooting.xlsx\")\n",
    "data2 = pd.read_excel(\"df_correcao2.xlsx\")\n",
    "print(len(df2))\n",
    "print(len(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = 0\n",
    "nok = 0\n",
    "for num_coluna in range(len(data2)):\n",
    "    if data.loc[num_coluna,'cause'] == data2.loc[num_coluna,'cause']:\n",
    "        ok += 1\n",
    "    else:\n",
    "        nok += 1\n",
    "\n",
    "print(ok)\n",
    "print(nok)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
