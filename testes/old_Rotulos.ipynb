{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def rotulo(txt):\n",
    "  req = f\"Preciso criar um modelo de IA que identifica qual problema o usuário está descrevendo. para isso irei te dar um problema que possuo em uma planilha, e preciso que vc me retorne uma lista python com o máximo de palavras chaves que você julgar importante para que o meu modelo na hora de classificar o texto do usuário, ele possa associar certo a esse problema, liste o máximo de palavras que conseguir, incluindo sinonimos, liste pelo menos 20 palavras. me retorne a resposta no seguinte formato: em um dicionário python onde a chave seria a frase certa e o valor seria uma lista python com as palavras chaves dessa frase. aqui esa as frases: {txt}\"\n",
    "\n",
    "  completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": req}\n",
    "    ]\n",
    "  )\n",
    "  res = completion.choices[0].message.content\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_excel(r'portugues\\pt_troubleshooting.xlsx')\n",
    "\n",
    "def obter_palavras_unicas(dataframe, coluna):\n",
    "    palavras_unicas = []\n",
    "    \n",
    "    # Itera sobre cada linha do DataFrame\n",
    "    for index, row in dataframe.iterrows():\n",
    "        # Obtém o valor da coluna desejada\n",
    "        texto = row[coluna]\n",
    "        \n",
    "        # Separa o texto em palavras\n",
    "        palavras = texto.split()\n",
    "        \n",
    "        # Adiciona as palavras únicas à lista\n",
    "        for palavra in palavras:\n",
    "            if palavra not in palavras_unicas:\n",
    "                palavras_unicas.append(palavra)\n",
    "    \n",
    "    return palavras_unicas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(r'portugues\\troubleshooting.xlsx')\n",
    "df2 = pd.read_excel(r'ingles\\en_troubleshooting.xlsx')\n",
    "list_df = [df1,df2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "equipament: coleta periodica offline\n",
      "linha: 0\n",
      "linha: 1\n",
      "linha: 2\n",
      "linha: 3\n",
      "linha: 4\n",
      "linha: 5\n",
      "linha: 6\n",
      "linha: 7\n",
      "linha: 8\n",
      "linha: 9\n",
      "linha: 10\n",
      "linha: 11\n",
      "linha: 12\n",
      "linha: 13\n",
      "linha: 14\n",
      "linha: 15\n",
      "linha: 16\n",
      "linha: 17\n",
      "linha: 18\n",
      "linha: 19\n",
      "linha: 20\n",
      "equipament: nan\n",
      "equipament: infraestrutura\n",
      "linha: 0\n",
      "linha: 1\n",
      "linha: 2\n",
      "linha: 3\n",
      "linha: 4\n",
      "linha: 5\n",
      "linha: 6\n",
      "linha: 7\n",
      "linha: 8\n",
      "linha: 9\n",
      "linha: 10\n",
      "linha: 11\n",
      "equipament: mysemeq\n",
      "linha: 0\n",
      "linha: 1\n",
      "linha: 2\n",
      "linha: 3\n",
      "linha: 4\n",
      "linha: 5\n",
      "linha: 6\n",
      "linha: 7\n",
      "linha: 8\n",
      "linha: 9\n",
      "linha: 10\n",
      "linha: 11\n",
      "linha: 12\n",
      "linha: 13\n",
      "linha: 14\n",
      "linha: 15\n",
      "linha: 16\n",
      "linha: 17\n",
      "linha: 18\n",
      "linha: 19\n",
      "linha: 20\n",
      "linha: 21\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID af7d3994d80b5a75938cd7a86ab93dd6 in your message.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 22\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     response \u001b[39m=\u001b[39m rotulo(row)\n\u001b[0;32m     23\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m, in \u001b[0;36mrotulo\u001b[1;34m(txt)\u001b[0m\n\u001b[0;32m      5\u001b[0m req \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPreciso criar um modelo de IA que identifica qual problema o usuário está descrevendo. para isso irei te dar um problema que possuo em uma planilha, e preciso que vc me retorne uma lista python com o máximo de palavras chaves que você julgar importante para que o meu modelo na hora de classificar o texto do usuário, ele possa associar certo a esse problema, liste o máximo de palavras que conseguir, incluindo sinonimos, liste pelo menos 20 palavras. me retorne a resposta no seguinte formato: em um dicionário python onde a chave seria a frase certa e o valor seria uma lista python com as palavras chaves dessa frase. aqui esa as frases: \u001b[39m\u001b[39m{\u001b[39;00mtxt\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m completion \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m      8\u001b[0m   model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      9\u001b[0m   messages\u001b[39m=\u001b[39;49m[\n\u001b[0;32m     10\u001b[0m     {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: req}\n\u001b[0;32m     11\u001b[0m   ]\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m res \u001b[39m=\u001b[39m completion\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\n",
      "File \u001b[1;32mc:\\Users\\herik\\OneDrive\\Área de Trabalho\\chatbot_hipotese\\.venv\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\herik\\OneDrive\\Área de Trabalho\\chatbot_hipotese\\.venv\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    138\u001b[0m (\n\u001b[0;32m    139\u001b[0m     deployment_id,\n\u001b[0;32m    140\u001b[0m     engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m     api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m )\n\u001b[1;32m--> 153\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m     url,\n\u001b[0;32m    156\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m     request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m     request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m )\n\u001b[0;32m    163\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m     \u001b[39m# must be an iterator\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\herik\\OneDrive\\Área de Trabalho\\chatbot_hipotese\\.venv\\lib\\site-packages\\openai\\api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    220\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    221\u001b[0m     method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    222\u001b[0m     url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m     request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    229\u001b[0m )\n\u001b[1;32m--> 230\u001b[0m resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    231\u001b[0m \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\herik\\OneDrive\\Área de Trabalho\\chatbot_hipotese\\.venv\\lib\\site-packages\\openai\\api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 624\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    625\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    626\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    627\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    628\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    629\u001b[0m         ),\n\u001b[0;32m    630\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    631\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\herik\\OneDrive\\Área de Trabalho\\chatbot_hipotese\\.venv\\lib\\site-packages\\openai\\api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 687\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    688\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    689\u001b[0m     )\n\u001b[0;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Rate limit reached for default-gpt-3.5-turbo in organization org-nmsKuDruu5029tBwE9hTIklz on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m60\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m     response \u001b[39m=\u001b[39m rotulo(row)\n\u001b[0;32m     26\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m     27\u001b[0m file_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpasta\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.json\u001b[39m\u001b[39m'\u001b[39m\n",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m, in \u001b[0;36mrotulo\u001b[1;34m(txt)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrotulo\u001b[39m(txt):\n\u001b[0;32m      5\u001b[0m   req \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPreciso criar um modelo de IA que identifica qual problema o usuário está descrevendo. para isso irei te dar um problema que possuo em uma planilha, e preciso que vc me retorne uma lista python com o máximo de palavras chaves que você julgar importante para que o meu modelo na hora de classificar o texto do usuário, ele possa associar certo a esse problema, liste o máximo de palavras que conseguir, incluindo sinonimos, liste pelo menos 20 palavras. me retorne a resposta no seguinte formato: em um dicionário python onde a chave seria a frase certa e o valor seria uma lista python com as palavras chaves dessa frase. aqui esa as frases: \u001b[39m\u001b[39m{\u001b[39;00mtxt\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m   completion \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m      8\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      9\u001b[0m     messages\u001b[39m=\u001b[39;49m[\n\u001b[0;32m     10\u001b[0m       {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: req}\n\u001b[0;32m     11\u001b[0m     ]\n\u001b[0;32m     12\u001b[0m   )\n\u001b[0;32m     13\u001b[0m   res \u001b[39m=\u001b[39m completion\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\n\u001b[0;32m     14\u001b[0m   \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\herik\\OneDrive\\Área de Trabalho\\chatbot_hipotese\\.venv\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\herik\\OneDrive\\Área de Trabalho\\chatbot_hipotese\\.venv\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\herik\\OneDrive\\Área de Trabalho\\chatbot_hipotese\\.venv\\lib\\site-packages\\openai\\api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    210\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    211\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    219\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    220\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    221\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    222\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    229\u001b[0m     )\n\u001b[1;32m--> 230\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    231\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\herik\\OneDrive\\Área de Trabalho\\chatbot_hipotese\\.venv\\lib\\site-packages\\openai\\api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    616\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    617\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    618\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    619\u001b[0m         )\n\u001b[0;32m    620\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    621\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 624\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    625\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    626\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    627\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    628\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    629\u001b[0m         ),\n\u001b[0;32m    630\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    631\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\herik\\OneDrive\\Área de Trabalho\\chatbot_hipotese\\.venv\\lib\\site-packages\\openai\\api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    685\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    686\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 687\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    688\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    689\u001b[0m     )\n\u001b[0;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID af7d3994d80b5a75938cd7a86ab93dd6 in your message.)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "cont = 0\n",
    "for df in list_df:\n",
    "    if cont == 0:\n",
    "        pasta = 'portugues/troubleshooting'\n",
    "        coluna = 'subject'\n",
    "    else:\n",
    "        pasta = 'ingles/en_troubleshooting'\n",
    "        coluna = 'equipament'\n",
    "\n",
    "    list_row = []\n",
    "    for i in df[coluna].unique():\n",
    "        print('equipament:', i)\n",
    "        df2 = df.loc[df[coluna]==i]\n",
    "        line = 0\n",
    "        for row in df2[coluna]:\n",
    "            if row not in list_row:\n",
    "                try:\n",
    "                    response = rotulo(row)\n",
    "                except:\n",
    "                    time.sleep(60)\n",
    "                    response = rotulo(row)\n",
    "                    continue\n",
    "                file_path = f'{pasta}/{i}.json'\n",
    "                if os.path.exists(file_path):\n",
    "                    with open(file_path, 'r+', encoding='utf-8') as f:\n",
    "                        log = json.load(f)\n",
    "                        log.append(response)\n",
    "                        f.seek(0)\n",
    "                        json.dump(log, f, indent=4)\n",
    "                else:\n",
    "                    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                        log = [response]\n",
    "                        json.dump(log, f, indent=4)\n",
    "                \n",
    "                print('linha:', line)\n",
    "                line += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rotulo('Bomba muito quente e piscando. Bomba agitando o fluido e não descarregando a água após um surto inicial e continuando a recircular.')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "for i in lista:\n",
    "    try:\n",
    "        response = rotulo(i)\n",
    "    except:\n",
    "        time.sleep(60)\n",
    "        response = rotulo(i)\n",
    "        continue\n",
    "    with open('response.json','r+',encoding='utf-8') as f:\n",
    "        log = json.load(f)\n",
    "        log.append(response)\n",
    "        f.seek(0)\n",
    "        json.dump(log, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
