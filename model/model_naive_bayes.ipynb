{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(dict,text):\n",
    "    # Preparação dos dados de treinamento\n",
    "    texts = text\n",
    "    labels = list(dict.keys())\n",
    "    # Criação do vetorizador usando as palavras-chave dos equipamentos\n",
    "    vectorizer = CountVectorizer(vocabulary=[keyword for keywords in dict.values() for keyword in keywords], ngram_range=(1, 2))\n",
    "    # Vetorização das descrições dos problemas\n",
    "    X_train = vectorizer.transform(texts)\n",
    "    # Criação do modelo MultinomialNB\n",
    "    model = MultinomialNB()\n",
    "    # Treinamento do modelo\n",
    "    model.fit(X_train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import sub\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.lang.pt.stop_words import STOP_WORDS\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_num(text):\n",
    "    text = sub(r'\\d+', '', text)\n",
    "    text = sub(r'\\s+', ' ',text)\n",
    "    return text\n",
    "\n",
    "def remove_punct(text):\n",
    "    text = sub(r\"[!#$%&'()*+,-./:;<=>?@[^_`{|}~]+\", ' ',text)\n",
    "    text = sub(r'\\s+', ' ',text)\n",
    "    return text\n",
    "\n",
    "def get_keywords(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    keywords = []\n",
    "    for word in tokens:\n",
    "        word = word.lower()\n",
    "        if word not in stopwords.words('portuguese') or word.lower() not in STOP_WORDS:\n",
    "            keywords.append(word)\n",
    "    return keywords\n",
    "\n",
    "def get_synonyms(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    synonyms = []\n",
    "    for word in tokens:\n",
    "        for syn in wordnet.synsets(word, lang=\"por\"):\n",
    "            for lemma in syn.lemmas(lang=\"por\"):\n",
    "                synonyms.append(lemma.name())\n",
    "    return synonyms\n",
    "\n",
    "def preprocess_lemma(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmas = []\n",
    "    for token in tokens:\n",
    "        lemmas.append(lemmatizer.lemmatize(token))\n",
    "    lemmas = ' '.join(lemmas)\n",
    "    return lemmas\n",
    "\n",
    "def remove_accent(text):\n",
    "    text = sub('[áàãâä]', 'a', sub('[éèêë]', 'e', sub('[íìîï]', 'i', sub('[óòõôö]', 'o', sub('[úùûü]', 'u', text)))))\n",
    "    text = sub(r'\\s+', ' ',text)\n",
    "    return text\n",
    "\n",
    "def preprocess_stem(text):\n",
    "    stemmer = SnowballStemmer(\"portuguese\")\n",
    "    tokens = word_tokenize(text)\n",
    "    stems = []\n",
    "    for token in tokens:\n",
    "        stems.append(stemmer.stem(token))\n",
    "    stems = ' '.join(stems)\n",
    "    return stems"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando o dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'..\\portugues\\pt_troubleshooting.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bombas',\n",
       " 'rolamentos',\n",
       " 'válvulas',\n",
       " 'acionamentos por corrente',\n",
       " 'caixas de engrenagens',\n",
       " 'Sistemas de óleo lubrificante',\n",
       " 'Acionamentos por correia em V',\n",
       " 'Sistemas de ventiladores',\n",
       " 'Purgadores de vapor',\n",
       " 'Motores elétricos',\n",
       " 'Contatos elétricos',\n",
       " 'Disjuntores elétricos de caixa moldada',\n",
       " 'Circuito magnético',\n",
       " 'Circuito dielétrico']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_equipament = []\n",
    "for equip in df['equipament']:\n",
    "    if equip not in class_equipament and equip != 'Motores elétricos (dc)':\n",
    "        class_equipament.append(equip)\n",
    "class_equipament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grupo_equipamentos = ['bombas',\n",
    "                     'rolamentos',\n",
    "                     'válvulas',\n",
    "                     'acionamentos por corrente',\n",
    "                     'caixas de engrenagens',\n",
    "                     'Sistemas de óleo lubrificante',\n",
    "                     'Acionamentos por correia em V',\n",
    "                     'Sistemas de ventiladores',\n",
    "                     'Purgadores de vapor',\n",
    "                     'Motores elétricos']\n",
    "\n",
    "grupo_componentes = ['Contatos elétricos',\n",
    "                     'Disjuntores elétricos de caixa moldada',\n",
    "                     'Circuito magnético',\n",
    "                     'Circuito dielétrico']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def similares(frase, lista_classes):\n",
    "    palavras_similares = []\n",
    "    palavras_frase = word_tokenize(frase.lower())\n",
    "\n",
    "    for palavra in palavras_frase:\n",
    "        similaridades = []\n",
    "        for classe in lista_classes:\n",
    "            similaridade = fuzz.ratio(palavra, classe)\n",
    "            similaridades.append((classe, similaridade))\n",
    "\n",
    "        similaridades = sorted(similaridades, key=lambda x: x[1], reverse=True)\n",
    "        if similaridades and similaridades[0][1] >= 80:\n",
    "            palavra_similar = {\n",
    "                \"palavra\": palavra,\n",
    "                \"classe\": similaridades[0][0],\n",
    "                \"similaridade\": similaridades[0][1]\n",
    "            }\n",
    "        else:\n",
    "            palavra_similar = {\n",
    "                \"palavra\": palavra,\n",
    "                \"classe\": None,\n",
    "                \"similaridade\": 0\n",
    "            }\n",
    "        \n",
    "        palavras_similares.append(palavra_similar)\n",
    "\n",
    "    return palavras_similares\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'palavra': 'bomba', 'classe': 'bombas', 'similaridade': 91},\n",
       " {'palavra': 'muito', 'classe': None, 'similaridade': 0},\n",
       " {'palavra': 'quente', 'classe': None, 'similaridade': 0},\n",
       " {'palavra': 'e', 'classe': None, 'similaridade': 0},\n",
       " {'palavra': 'piscando', 'classe': None, 'similaridade': 0},\n",
       " {'palavra': '.', 'classe': None, 'similaridade': 0},\n",
       " {'palavra': 'bomba', 'classe': 'bombas', 'similaridade': 91},\n",
       " {'palavra': 'agitando', 'classe': None, 'similaridade': 0},\n",
       " {'palavra': 'o', 'classe': None, 'similaridade': 0},\n",
       " {'palavra': 'fluido', 'classe': None, 'similaridade': 0},\n",
       " {'palavra': 'e', 'classe': None, 'similaridade': 0},\n",
       " {'palavra': 'não', 'classe': None, 'similaridade': 0},\n",
       " {'palavra': 'descarregando', 'classe': None, 'similaridade': 0},\n",
       " {'palavra': 'a', 'classe': None, 'similaridade': 0},\n",
       " {'palavra': 'água', 'classe': None, 'similaridade': 0},\n",
       " {'palavra': 'após', 'classe': None, 'similaridade': 0},\n",
       " {'palavra': 'um', 'classe': None, 'similaridade': 0},\n",
       " {'palavra': 'surto', 'classe': None, 'similaridade': 0},\n",
       " {'palavra': 'inicial', 'classe': None, 'similaridade': 0},\n",
       " {'palavra': 'e', 'classe': None, 'similaridade': 0},\n",
       " {'palavra': 'continuando', 'classe': None, 'similaridade': 0},\n",
       " {'palavra': 'a', 'classe': None, 'similaridade': 0},\n",
       " {'palavra': 'recircular', 'classe': None, 'similaridade': 0},\n",
       " {'palavra': '.', 'classe': None, 'similaridade': 0}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto = \"Bomba muito quente e piscando. Bomba agitando o fluido e não descarregando a água após um surto inicial e continuando a recircular.\"\n",
    "lista_classes = ['bombas',\n",
    "                     'rolamentos',\n",
    "                     'válvulas',\n",
    "                     'acionamentos por corrente',\n",
    "                     'caixas de engrenagens',\n",
    "                     'Sistemas de óleo lubrificante',\n",
    "                     'Acionamentos por correia em V',\n",
    "                     'Sistemas de ventiladores',\n",
    "                     'Purgadores de vapor',\n",
    "                     'Motores elétricos']\n",
    "\n",
    "resultado = similares(texto, lista_classes)\n",
    "resultado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
