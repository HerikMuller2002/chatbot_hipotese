{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = [\n",
    "    # \"Cumprimentos e saudações\",\n",
    "    # \"Solicitação de ajuda para solucionar um problema\",\n",
    "    # \"Pedido de resolução do problema\",\n",
    "    # \"Dúvida na identificação do equipamento\",\n",
    "    # \"Dúvida na identificação do problema\",\n",
    "    \"Pedido de esclarecimento\",\n",
    "    \"Feedback sobre a solução fornecida\",\n",
    "    \"Reclamação ou insatisfação\",\n",
    "    \"Agradecimento\",\n",
    "    \"Encerramento da conversa\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "\n",
    "def create_json(json_path, content):\n",
    "    if os.path.isfile(json_path):\n",
    "        with open(json_path, 'r+', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            data.append(content)\n",
    "            f.seek(0)\n",
    "            json.dump(data, f, indent=4)\n",
    "    else:\n",
    "        with open(json_path, 'w', encoding='utf-8') as f:\n",
    "            data = [content]\n",
    "            json.dump(data, f, indent=4)\n",
    "\n",
    "def chatgpt(txt):\n",
    "  openai.api_key = \"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\"\n",
    "  completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": txt}\n",
    "    ]\n",
    "  )\n",
    "  response = completion.choices[0].message.content\n",
    "  return response\n",
    "\n",
    "def generation(df, qtd_samples, path):\n",
    "    for row in df:\n",
    "        samples = []\n",
    "        while len(samples) < qtd_samples:\n",
    "            retry = True\n",
    "            while retry:\n",
    "                try:\n",
    "                    response = chatgpt(f\"simule ser um especialista em chatbot e pln além de ser especialista em problemas mecânicos e elétricos. agora me dê 20 exemplos de textos que o usuário escreveria (dentro do contextro de chatbot de soluções de problemas industriais), relacionados a essa intenção: {row}. Retorne a resposta em uma lista python!!!! (apenas o corpo da lista, sem variável ou texto complementar), exemplo: ['sample1','sample2','sample3'...]\")\n",
    "                except:\n",
    "                    time.sleep(60)\n",
    "                    response = chatgpt(f\"simule ser um especialista em chatbot e pln além de ser especialista em problemas mecânicos e elétricos. agora me dê 20 exemplos de textos que o usuário escreveria (dentro do contextro de chatbot de soluções de problemas industriais), relacionados a essa intenção: {row}. Retorne a resposta em uma lista python!!!! (apenas o corpo da lista, sem variável ou texto complementar), exemplo: ['sample1','sample2','sample3'...]\")\n",
    "                try:\n",
    "                    if type(eval(response)) == list:\n",
    "                        samples += eval(response)\n",
    "                        samples = list(set(samples))\n",
    "                        retry = False\n",
    "                    else:\n",
    "                        continue\n",
    "                except:\n",
    "                    continue\n",
    "        if len(samples) > qtd_samples:\n",
    "            samples = random.sample(samples, qtd_samples)\n",
    "        dict_ = {'label':row, 'keywords':samples}\n",
    "        create_json(path,dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Rate limit reached for default-gpt-3.5-turbo in organization org-nmsKuDruu5029tBwE9hTIklz on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 37\u001b[0m, in \u001b[0;36mgeneration\u001b[1;34m(df, qtd_samples, path)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 37\u001b[0m     response \u001b[39m=\u001b[39m chatgpt(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msimule ser um especialista em chatbot e pln além de ser especialista em problemas mecânicos e elétricos. agora me dê 20 exemplos de textos que o usuário escreveria (dentro do contextro de chatbot de soluções de problemas industriais), relacionados a essa intenção: \u001b[39;49m\u001b[39m{\u001b[39;49;00mrow\u001b[39m}\u001b[39;49;00m\u001b[39m. Retorne a resposta em uma lista python!!!! (apenas o corpo da lista, sem variável ou texto complementar), exemplo: [\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msample1\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msample2\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msample3\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m...]\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     38\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[2], line 21\u001b[0m, in \u001b[0;36mchatgpt\u001b[1;34m(txt)\u001b[0m\n\u001b[0;32m     20\u001b[0m openai\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msk-T4bQU5sF4AUXk5tSbue8T3BlbkFJloxWo0Kg1uE5pQ2A72m4\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 21\u001b[0m completion \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m     22\u001b[0m   model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     23\u001b[0m   messages\u001b[39m=\u001b[39;49m[\n\u001b[0;32m     24\u001b[0m     {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: txt}\n\u001b[0;32m     25\u001b[0m   ]\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     27\u001b[0m response \u001b[39m=\u001b[39m completion\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\n",
      "File \u001b[1;32mc:\\Users\\herik\\OneDrive\\Área de Trabalho\\chatbot_hipotese\\.venv\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\herik\\OneDrive\\Área de Trabalho\\chatbot_hipotese\\.venv\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    138\u001b[0m (\n\u001b[0;32m    139\u001b[0m     deployment_id,\n\u001b[0;32m    140\u001b[0m     engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m     api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m )\n\u001b[1;32m--> 153\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m     url,\n\u001b[0;32m    156\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m     request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m     request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m )\n\u001b[0;32m    163\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m     \u001b[39m# must be an iterator\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\herik\\OneDrive\\Área de Trabalho\\chatbot_hipotese\\.venv\\lib\\site-packages\\openai\\api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    220\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    221\u001b[0m     method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    222\u001b[0m     url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m     request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    229\u001b[0m )\n\u001b[1;32m--> 230\u001b[0m resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    231\u001b[0m \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\herik\\OneDrive\\Área de Trabalho\\chatbot_hipotese\\.venv\\lib\\site-packages\\openai\\api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 624\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    625\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    626\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    627\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    628\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    629\u001b[0m         ),\n\u001b[0;32m    630\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    631\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\herik\\OneDrive\\Área de Trabalho\\chatbot_hipotese\\.venv\\lib\\site-packages\\openai\\api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 687\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    688\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    689\u001b[0m     )\n\u001b[0;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Rate limit reached for default-gpt-3.5-turbo in organization org-nmsKuDruu5029tBwE9hTIklz on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m new_df \u001b[39m=\u001b[39m generation(df,\u001b[39m100\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mintents_samples.json\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[2], line 40\u001b[0m, in \u001b[0;36mgeneration\u001b[1;34m(df, qtd_samples, path)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m60\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m     response \u001b[39m=\u001b[39m chatgpt(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msimule ser um especialista em chatbot e pln além de ser especialista em problemas mecânicos e elétricos. agora me dê 20 exemplos de textos que o usuário escreveria (dentro do contextro de chatbot de soluções de problemas industriais), relacionados a essa intenção: \u001b[39;49m\u001b[39m{\u001b[39;49;00mrow\u001b[39m}\u001b[39;49;00m\u001b[39m. Retorne a resposta em uma lista python!!!! (apenas o corpo da lista, sem variável ou texto complementar), exemplo: [\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msample1\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msample2\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msample3\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m...]\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     41\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39meval\u001b[39m(response)) \u001b[39m==\u001b[39m \u001b[39mlist\u001b[39m:\n",
      "Cell \u001b[1;32mIn[2], line 21\u001b[0m, in \u001b[0;36mchatgpt\u001b[1;34m(txt)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mchatgpt\u001b[39m(txt):\n\u001b[0;32m     20\u001b[0m   openai\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msk-T4bQU5sF4AUXk5tSbue8T3BlbkFJloxWo0Kg1uE5pQ2A72m4\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 21\u001b[0m   completion \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m     22\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     23\u001b[0m     messages\u001b[39m=\u001b[39;49m[\n\u001b[0;32m     24\u001b[0m       {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: txt}\n\u001b[0;32m     25\u001b[0m     ]\n\u001b[0;32m     26\u001b[0m   )\n\u001b[0;32m     27\u001b[0m   response \u001b[39m=\u001b[39m completion\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\n\u001b[0;32m     28\u001b[0m   \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\herik\\OneDrive\\Área de Trabalho\\chatbot_hipotese\\.venv\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\herik\\OneDrive\\Área de Trabalho\\chatbot_hipotese\\.venv\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\herik\\OneDrive\\Área de Trabalho\\chatbot_hipotese\\.venv\\lib\\site-packages\\openai\\api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    210\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    211\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    219\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    220\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    221\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    222\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    229\u001b[0m     )\n\u001b[1;32m--> 230\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    231\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\herik\\OneDrive\\Área de Trabalho\\chatbot_hipotese\\.venv\\lib\\site-packages\\openai\\api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    616\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    617\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    618\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    619\u001b[0m         )\n\u001b[0;32m    620\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    621\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 624\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    625\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    626\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    627\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    628\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    629\u001b[0m         ),\n\u001b[0;32m    630\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    631\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\herik\\OneDrive\\Área de Trabalho\\chatbot_hipotese\\.venv\\lib\\site-packages\\openai\\api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    685\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    686\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 687\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    688\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    689\u001b[0m     )\n\u001b[0;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Rate limit reached for default-gpt-3.5-turbo in organization org-nmsKuDruu5029tBwE9hTIklz on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method."
     ]
    }
   ],
   "source": [
    "new_df = generation(df,100,'intents_samples.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
