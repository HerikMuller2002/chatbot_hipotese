{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def rotulo(txt):\n",
    "  req = f\"Preciso criar um modelo de IA que identifica qual problema o usuário está descrevendo. para isso irei te dar um problema que possuo em uma planilha, e preciso que vc me retorne uma lista python com o máximo de palavras chaves que você julgar importante para que o meu modelo na hora de classificar o texto do usuário, ele possa associar certo a esse problema, liste o máximo de palavras que conseguir, incluindo sinonimos, liste pelo menos 20 palavras. me retorne a resposta no seguinte formato: em um dicionário python onde a chave seria a frase certa e o valor seria uma lista python com as palavras chaves dessa frase. aqui esa as frases: {txt}\"\n",
    "\n",
    "  completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": req}\n",
    "    ]\n",
    "  )\n",
    "  res = completion.choices[0].message.content\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_excel(r'portugues\\pt_troubleshooting.xlsx')\n",
    "\n",
    "def obter_palavras_unicas(dataframe, coluna):\n",
    "    palavras_unicas = []\n",
    "    \n",
    "    # Itera sobre cada linha do DataFrame\n",
    "    for index, row in dataframe.iterrows():\n",
    "        # Obtém o valor da coluna desejada\n",
    "        texto = row[coluna]\n",
    "        \n",
    "        # Separa o texto em palavras\n",
    "        palavras = texto.split()\n",
    "        \n",
    "        # Adiciona as palavras únicas à lista\n",
    "        for palavra in palavras:\n",
    "            if palavra not in palavras_unicas:\n",
    "                palavras_unicas.append(palavra)\n",
    "    \n",
    "    return palavras_unicas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(r'portugues\\troubleshooting.xlsx')\n",
    "df2 = pd.read_excel(r'ingles\\en_troubleshooting.xlsx')\n",
    "list_df = [df1,df2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "cont = 0\n",
    "for df in list_df:\n",
    "    if cont == 0:\n",
    "        pasta = 'portugues/troubleshooting'\n",
    "        coluna = 'subject'\n",
    "    else:\n",
    "        pasta = 'ingles/en_troubleshooting'\n",
    "        coluna = 'equipament'\n",
    "\n",
    "    list_row = []\n",
    "    for i in df[coluna].unique():\n",
    "        print('equipament:', i)\n",
    "        df2 = df.loc[df[coluna]==i]\n",
    "        line = 0\n",
    "        for row in df2[coluna]:\n",
    "            if row not in list_row:\n",
    "                try:\n",
    "                    response = rotulo(row)\n",
    "                except:\n",
    "                    time.sleep(60)\n",
    "                    response = rotulo(row)\n",
    "                    continue\n",
    "                file_path = f'{pasta}/{i}.json'\n",
    "                if os.path.exists(file_path):\n",
    "                    with open(file_path, 'r+', encoding='utf-8') as f:\n",
    "                        log = json.load(f)\n",
    "                        log.append(response)\n",
    "                        f.seek(0)\n",
    "                        json.dump(log, f, indent=4)\n",
    "                else:\n",
    "                    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                        log = [response]\n",
    "                        json.dump(log, f, indent=4)\n",
    "                \n",
    "                print('linha:', line)\n",
    "                line += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rotulo('Bomba muito quente e piscando. Bomba agitando o fluido e não descarregando a água após um surto inicial e continuando a recircular.')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "for i in lista:\n",
    "    try:\n",
    "        response = rotulo(i)\n",
    "    except:\n",
    "        time.sleep(60)\n",
    "        response = rotulo(i)\n",
    "        continue\n",
    "    with open('response.json','r+',encoding='utf-8') as f:\n",
    "        log = json.load(f)\n",
    "        log.append(response)\n",
    "        f.seek(0)\n",
    "        json.dump(log, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
